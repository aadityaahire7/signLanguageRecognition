# signLanguageRecognition

Sign Language is an essential form of communication for people having difficulties with hearing.  Automated systems that recognise and interpret sign gestures close the communication gap, and enable people with hearing loss to interact more successfully with the community.A system for sign language recognition has been created in this project. Through the conversion of sign gestures into textual information, sign language recognition is a useful tool that helps people with difficulties with hearing.Convolutional Neural Networks (CNNs) are used in this system, and it is enhanced with an appealing Graphical User Interface (GUI) to facilitate user-friendly interaction.
The projects's basis is the use of convolutional neural networks in image recognition. The ability of CNNs to identify patterns in images regardless of their placement is advantageous for classifying signs in sign language since signs can appear in many places within an image. CNNs therefore are well-suited for image identification tasks, which makes them perfect for deciphering sign language actions that have been captured in a picture. The dataset used to train the model includes pictures of different sign language symbols, each connected to a distinct alphabet. Individuals are able to interact and test different images with the trained model with the help of Graphical User Interface.

